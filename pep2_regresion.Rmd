---
title: "pep2 regresion"
author: "Forma 6"
date: "2024-01-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

El gobierno también quiere saber si es posible construir un modelo predictivo del consumo eléctrico d elos hogares chilenos con un error menor a 2 Kwh con la misma muestra proporcionada.

Se pide construir un modelo de regresión adecuado para responder la pregunta asignada que use entre 2 y 5 predictores, asegurando que el modelo obtenido sea confiable (Considere VIF >= 5 como evidencia de multicolinealidad problemática). Determine si la calidad predictiva del modelo satisface los requerimientos del gobierno evalúandolo con 499 iteraciones de bootstrapping (usando la semilla 131)

```{r Definir semilla}
library(car)
library(dplyr)
library(ggpubr)
library(psych)

# Definimos semilla
set.seed(131)

# Leemos los datos
datos <- read.csv("EI-2024-2-PE2-Datos-Forma-06.csv")

# Con la funcion str verificamos que el tipo de datos esté correcto
str(datos)

# Notamos que macro_zona, franja y sobre_cons hay que convertirlos a factores puesto que son variables categoricas/dicotómicas
datos$macro_zona <- as.factor(datos$macro_zona)
datos$franja <- as.factor(datos$franja)
datos$sobre_cons <- as.factor(datos$sobre_cons)

str(datos)

# Seleccionamos datos de entrenamiento y de prueba
datos_entren <- datos[1:70,] # fila 1 a 70 y todas las columnas
datos_prueba <- datos[71:100,]
```

Con los datos ya filtrados preparamos la variable de respuesta y los predictores

```{r Seleccionar predictor}
nombre_respuesta <- "consumo"

# Extraer solo las columnas numéricas para revisar correlación
datos_num <- datos_entren[, sapply(datos_entren, is.numeric)]

i_respuesta_resto <- which(colnames(datos_num)==nombre_respuesta) # Indice de la columna de la var de rpta

# Calcular la matriz de correlación
correlacion <- cor(datos_num[ , -i_respuesta_resto], y = datos_num[[nombre_respuesta]])

cat("Correlacion con consumo:\n")
print(correlacion)
```
Asumiendo que el mejor predictor sería el que tiene la mayor correlacion con la variable de respuesta entonces seleccionamos el máximo

```{r seleccionar maximo}
i_mejor <- which(correlacion == max(abs(correlacion)))

# Seleccionamos 9no predictor
#predictor <- colnames(datos_resto)[i_mejor]
predictor <- rownames(correlacion)[i_mejor]
cat("La variable seleccionada es: ",predictor)
```




```{r Ajuste del modelo}
# Definimos modelo mínimo, en este caso modelo nulo
modelo_nulo <- lm(consumo ~ 1, data = datos_entren)

# Definimos modelo máximo, en este caso consideramos a todas las variables
modelo_rlm_max <- lm(consumo ~ . ,data = datos_entren)

modelo_rlm <- step(modelo_nulo, scope = list(lower = modelo_nulo, upper = modelo_rlm_max),
               direction = "both",
               test = "F", trace = 1)

# Mostrar los coeficientes del modelo conseguido
cat("\nModelo obtenido:\n")
print(modelo_rlm[["coefficients"]])
```

Notamos que se seleccionaron 7 variables cuando debimos obtener entre 2 y 5 por lo que tendremos que eliminar dos de las que ya están agregadas y esto lo haremos mediante una eliminacion hacia atrás a la variable que tenga el menor F-value

En este caso notamos que sucede con res_term por lo que lo quitaremos del modelo

```{r}
# Actualizamos el modelo quitando res_term
modelo_rlm <- update(modelo_rlm, . ~ . - res_term)
print(summary(modelo_rlm))
```

Notamos que ahora correspondería quitar n_elec_gr

```{r}
# Actualizamos el modelo quitando res_term
modelo_rlm <- update(modelo_rlm, . ~ . - n_elect_gr)
print(summary(modelo_rlm))
```

y con esto ya cumplimos con que el modelo posee entre 2 y 5 predictores

---

Evaluando la confiabilidad del modelo conseguido...

  1. Que no existan niveles inaceptables de multicolineadlidad
  2. Prueba de curvatura
  3. Normalidad de los residuos
  4. Prueba de homocedasticidad
  5. Prueba de independecia de los residuos
  6. Revisar que relaciones entre predictores y var de rpta sean aproximadamente lineales



