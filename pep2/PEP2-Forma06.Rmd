---
title: "Forma06"
authors: "20.915.795-0, 21.081.166-4"
output: html_document
date: "2025-01-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(dplyr)
library(ggplot2)
library(boot)
library(car)
library(ggpubr)
```

# Pregunta 1

El Gobierno realizó un estudio para concer el consumo de energía eléctrica promedio  de los hogares chilenos. Con la intención de determinar la cobertura del subsidio de energía eléctrica que se discute en el Congreso, el Gobierno necesita saber si la proporción de viviendas DFL2 (es decir de hasta 120 m2) que pagan el temido "cargo por sobreconsumo" de la macrozona centro es similar al de la macrozona sur. Con este fin, ha proporcionado una muestra aleatoria de 100 hogares estudiados con las siguientes variables:

Para responder esta pregunta, se pide reaizar un análisis inferencial usando remuestreo con permutaciones (100 repeticiones) y 95% de confianza, explicando y justificando paso a paso el procedimiento seguido, incluyendo las hiótesis contrastadas y la interpretación de los resultados obtenidos para la pregunta del Gobierno.

## Respuesta
```{r}
# Leemos los datos
datos <- read.csv("EI-2024-2-PE2-Datos-Forma-06.csv")
datos$macro_zona <- as.factor(datos$macro_zona)
datos$franja <- as.factor(datos$franja)

str(datos)

set.seed(131)
```

### Planteamiento de hipótesis:
H0: La proporción de viviendas DFL2 que pagan el "cargo por sobreconsumo" en la macrozona centro es igual a la proporción en la macrozona sur. 
Ha: La proporción de viviendas DFL2 que pagan el "cargo por sobreconsumo" en la macrozona centro es diferente a la proporción en la macrozona sur.

H0: p_centro = p_sur
Ha: p_centro != p_sur

Siendo p_centro y p_sur las proporciones de viviendas DFL2 que pagan el "cargo por sobreconsumo" en la macrozona centro y sur, respectivamente.

Para contrastar estas hipótesis en base a lo que dice el enunciado utilizaremos un nivel de confianza del 95%.

Obtenemos los datos relevantes:

```{r}
# Filtrar viviendas DFL2 (superficie <= 120 m2)
data_DFL2 <- subset(datos, superf <= 120)

# Separar datos por macrozona (centro y sur)
centro <- subset(data_DFL2, macro_zona == "centro")
sur <- subset(data_DFL2, macro_zona == "sur")
```

### Estadístico de prueba:

El estadístico a utilizar para docimar las hipótesis propuestas es la diferencia en proporciones de sobreconsumo entre la macrozona centro y sur, ya que es el más relevante en base a lo que estamos buscando.
```{r}
# Calcular proporción de sobreconsumo en cada macrozona
prop_centro <- mean(centro$sobre_cons == "si")
prop_sur <- mean(sur$sobre_cons == "si")

# Diferencia observada en proporciones
diff_obs <- prop_centro - prop_sur

cat("Diferencia observada en proporciones:", diff_obs, "\n")
```


### Remuestreo
A continuación, realizamos el análisis inferencial mediante remuestreo con permutaciones:

Combinamos los datos de ambas macrozonas:

```{r}
# Crear la columna combinada para remuestreo
data_combined <- data_DFL2[, c("macro_zona", "sobre_cons")]
```

Realizamos las 100 permutaciones:
```{r}
perm_test <- function(data, n_perm = 100) {
  diff_perm <- numeric(n_perm)
  
  for (i in 1:n_perm) {
    # Permutar las etiquetas de macrozona
    data$macro_zona <- sample(data$macro_zona)
    
    # Recalcular proporciones con las etiquetas permutadas
    prop_centro_perm <- mean(data[data$macro_zona == "centro", "sobre_cons"] == "si")
    prop_sur_perm <- mean(data[data$macro_zona == "sur", "sobre_cons"] == "si")
    
    # Guardar la diferencia en proporciones
    diff_perm[i] <- prop_centro_perm - prop_sur_perm
  }
  
  return(diff_perm)
}

# Ejecutar 100 permutaciones
n_permutations <- 100
diff_permuted <- perm_test(data_combined, n_perm = n_permutations)

# Creamos un histograma para visualizar la distribución de las diferencias
hist(diff_permuted, breaks = 20, main = "Distribución de diferencias (perm.)",
     xlab = "Diferencia de proporciones", col = "lightblue")
abline(v = diff_obs, col = "red", lwd = 2, lty = 2)  # Línea para la diferencia observada

```

Ahora con las permutaciones realizadas, calculamos el p-value para contrastar las hipótesis:
```{r}
p_value <- mean(abs(diff_permuted) >= abs(diff_obs))

cat("P-valor:", p_value, "\n")
```

Como vemos, obtenemos un p-value de 0.53, como estamos utilizando un intervalo de confianza del 95%, y el p-value es mayor a 0.05, no podemos rechazar la hipótesis nula. Por lo tanto, no hay evidencia suficiente para afirmar que la proporción de viviendas DFL2 que pagan el "cargo por sobreconsumo" en la macrozona centro es diferente a la proporción en la macrozona sur.

## Pregunta 2

El gobierno también quiere saber si es posible construir un modelo predictivo del consumo eléctrico d elos hogares chilenos con un error menor a 2 Kwh con la misma muestra proporcionada.

Se pide construir un modelo de regresión adecuado para responder la pregunta asignada que use entre 2 y 5 predictores, asegurando que el modelo obtenido sea confiable (Considere VIF >= 5 como evidencia de multicolinealidad problemática). Determine si la calidad predictiva del modelo satisface los requerimientos del gobierno evalúandolo con 499 iteraciones de bootstrapping (usando la semilla 131)

### Respuesta

```{r}
# Seleccionamos datos de entrenamiento y de prueba
datos_entren <- datos[1:70,] # fila 1 a 70 y todas las columnas
datos_prueba <- datos[71:100,]
```

Con los datos ya filtrados preparamos la variable de respuesta y los predictores

```{r Seleccionar predictor}
nombre_respuesta <- "consumo"

# Extraer solo las columnas numéricas para revisar correlación
datos_num <- datos_entren[, sapply(datos_entren, is.numeric)]

i_respuesta_resto <- which(colnames(datos_num)==nombre_respuesta) # Indice de la columna de la var de rpta

# Calcular la matriz de correlación
correlacion <- cor(datos_num[ , -i_respuesta_resto], y = datos_num[[nombre_respuesta]])

cat("Correlacion con consumo:\n")
print(correlacion)
```
Asumiendo que el mejor predictor sería el que tiene la mayor correlacion con la variable de respuesta entonces seleccionamos el máximo

```{r seleccionar maximo}
i_mejor <- which(correlacion == max(abs(correlacion)))

# Seleccionamos 9no predictor
#predictor <- colnames(datos_resto)[i_mejor]
predictor <- rownames(correlacion)[i_mejor]
cat("La variable seleccionada es: ",predictor)
```




```{r Ajuste del modelo}
# Definimos modelo mínimo, en este caso modelo nulo
modelo_nulo <- lm(consumo ~ 1, data = datos_entren)

# Definimos modelo máximo, en este caso consideramos a todas las variables
modelo_rlm_max <- lm(consumo ~ . ,data = datos_entren)

modelo_rlm <- step(modelo_nulo, scope = list(lower = modelo_nulo, upper = modelo_rlm_max),
               direction = "both",
               test = "F", trace = 1)

# Mostrar los coeficientes del modelo conseguido
cat("\nModelo obtenido:\n")
print(modelo_rlm[["coefficients"]])
```

Notamos que se seleccionaron 7 variables cuando debimos obtener entre 2 y 5 por lo que tendremos que eliminar dos de las que ya están agregadas y esto lo haremos mediante una eliminacion hacia atrás a la variable que tenga el menor F-value

En este caso notamos que sucede con res_term por lo que lo quitaremos del modelo

```{r}
# Actualizamos el modelo quitando res_term
modelo_rlm <- update(modelo_rlm, . ~ . - res_term)
print(summary(modelo_rlm))
```

Notamos que ahora correspondería quitar n_elec_gr

```{r}
# Actualizamos el modelo quitando res_term
modelo_rlm <- update(modelo_rlm, . ~ . - n_elec_gr)
print(summary(modelo_rlm))
```

y con esto ya cumplimos con que el modelo posee entre 2 y 5 predictores

---

Evaluando la confiabilidad del modelo conseguido...

  1. Que no existan niveles inaceptables de multicolineadlidad
  2. Prueba de curvatura
  3. Normalidad de los residuos
  4. Prueba de homocedasticidad
  5. Prueba de independecia de los residuos
  6. Revisar que relaciones entre predictores y var de rpta sean aproximadamente lineales

```{r Que no existan niveles inaceptables de multicolineadlidad}
cat("Factores de inflación de la varianza:\n")
print(vif(modelo_rlm))
cat("Estadísticos de tolerancia:\n")
print(1 / vif(modelo_rlm))
```
Vemos que hay indicios de multicolinealidad problemática en 2 casos:

- horas_uso
- superf

Eliminemos la que presenta el mayor valor y luego sigamos evaluando.

```{r Eliminemos el que presenta multicolinealidad moderada}
rlm <- update(modelo_rlm, . ~ . - horas_uso)

cat("Factores de inflación de la varianza:\n")
print(vif(rlm))
cat("Estadísticos de tolerancia:\n")
print(1 / vif(rlm))
```
Notamos que ahora todos los predictores presentan un VIF menor a 5, hemos eliminado gran parte de la multicolinealidad presente en el modelo anterior manteniendo 4 predictores.


Revisemos la prueba de curvatura para este modelo

```{r Prueba de curvatura RLM}
cat("Prueba de curvatura:\n")
residualPlots(modelo_rlm, type = "rstandard", terms = ~ 1, col = "steelblue", pch = 20, col.quad = "red")
```

Se ve cierta curvatura, pero no se ve un patrón preocupante, aunque existe cierta tendencia a patrones por sobre la línea de regresión. La prueba de curvatura también apunta en este sentido y segun el p-valor es mayor a 0.05 por lo que esto sugiere que no se detecta curvatura.

Revisemos ahora la normalidad de los residuos

```{r Normalidad de residuos}
# Grafico qq
qq_res <- ggqqplot(data.frame(Residuos = resid(modelo_rlm)), x = "Residuos", color = "steelblue")
print(qq_res)

sw_res <- shapiro.test(resid(modelo_rlm))
cat("Test de normalidad de los residuos del modelo de RLM:")
print(sw_res)
```

Como p > 0.05 no hay suficiente evidencia para rechazar que los datos siguen una distribucion normal

Ahora verifiquemos la varianza e independencia de los residuos.

```{r Ahora verifiquemos la varianza e independencia de los residuos}
cat("Prueba de varianza del error no constante:\n")
ncvTest(modelo_rlm)

cat("\nIndependencia de los residuos\n")
print(durbinWatsonTest(modelo_rlm))
```

Nos damos cuenta de que entonces la homocedasticidad no se está cumpliendo pero que los residuos sí son independientes.

**Verifiquemos entonces la influencia de valores atípicos** que puedan estar generando esto  mediante la **Distancia de Cook** con el gráfico influencePlot

```{r Valores atipicos}
# Desplegar gráficos de influencia
casos_influyentes <- influencePlot(modelo_rlm, id = list(n = 3))
cat("\nCasos que podrían ser influyentes:\n")
print(casos_influyentes)

```

Notamos que el caso que podría tener mayor influencia atípica es el 65

horas_uso  temp_inv    superf  temp_ver edad_elec 

```{r Verificar si quitar caso influyente}
crPlots(modelo_rlm,
        col = "steelblue", pch = 20, col.lines = c("red", "steelblue"),
        smooth = list(smoother = loessLine, span = 1),
        id = list(method = "r", n = 8, cex = 0.7, location = "lr"))

modelo_rlm2 <- lm(consumo ~ horas_uso + temp_inv + superf + edad_elec, data = datos_entren[-65, ])
crPlots(modelo_rlm,
        col = "steelblue", pch = 20, col.lines = c("red", "steelblue"),
        smooth = list(smoother = loessLine, span = 1),
        id = list(method = "r", n = 8, cex = 0.7, location = "lr"))
```

Ahora verifiquemos nuevamente

```{r Ahora verifiquemos la varianza e independencia de los residuos}
cat("Prueba de varianza del error no constante:\n")
ncvTest(modelo_rlm2)

cat("\nIndependencia de los residuos\n")
print(durbinWatsonTest(modelo_rlm2))
```
quitar el caso 65 nos sirvio para que se cumpla la homocedasticidad

Con esto el modelo cumpliendo con las condiciones antes mencionadas quedaría:

```{r}
print(summary(modelo_rlm2))
```

Y notamos que se cumple tener un Residual Standard error como se pide en el enunciado

---

Ahora determinamos la calidad predictiva del modelo con bootstrapping:

```{r}
# Definir una función para calcular el RMSE con remuestreo y ajuste del modelo
calc_rmse <- function(data, indices) {
  # Crear una muestra remuestreada
  bootstrap_data <- data[indices, ]
  
  # Ajustar el modelo a los datos remuestreados
  modelo_boot <- lm(consumo ~ horas_uso + temp_inv + superf + edad_elec, data = bootstrap_data)
  
  # Predecir sobre los datos de prueba originales
  predicciones <- predict(modelo_boot, newdata = datos_prueba)
  
  # Calcular RMSE
  errores <- datos_prueba$consumo - predicciones
  rmse <- sqrt(mean(errores^2, na.rm = TRUE))
  
  return(rmse)
}

# Realizar el bootstrapping
set.seed(131)  # Fijar semilla para reproducibilidad
boot_results <- boot(data = datos_entren, statistic = calc_rmse, R = 499)

# Mostrar los resultados del bootstrapping
cat("Estimación del RMSE mediante bootstrapping:\n")
print(boot_results)

# Calcular el intervalo de confianza del 95% para el RMSE
ci <- boot.ci(boot_results, type = "perc")
cat("Intervalo de confianza del 95% para el RMSE:\n")
print(ci)

# Evaluar si el modelo cumple con los requerimientos del gobierno
if (!is.null(ci$percent) && ci$percent[5] < 2) {
  cat("El modelo satisface los requerimientos del gobierno (error menor a 2 Kwh).\n")
} else {
  cat("El modelo NO satisface los requerimientos del gobierno (error mayor a 2 Kwh).\n")
}

```
El modelo es apto para ser utilizado como una herramienta predictiva confiable para el consumo eléctrico. El modelo puede serimplementado en la toma de decisiones relacionadas con el subsidio de energía eléctrica.
