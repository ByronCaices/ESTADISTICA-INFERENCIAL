---
title: "Lectura 14"
author: "Byron Caices"
date: "2024-12-29"
output: html_document
---

### Modelo de RLM

```{r RLM para predecir potencia de motor a partir de volumen util de cil y peso del vehiculo}
library(dplyr)
library(scatterplot3d)

# Cargar y filtrar los datos
datos <- mtcars %>% filter(wt > 2 & wt < 5)

# Ajustar modelo de RLM
modelo <- lm(hp ~ disp + wt, data = datos)
print(summary(modelo))


# Graficar modelo ajustado, diferencia valores sobre y bajo el plano
i_color <- 1 + (resid(modelo)>0)
g <- scatterplot3d(
  datos[["disp"]], datos[["wt"]], datos[["hp"]], type="p", angle=60,
  pch = 16,color = c("darkorange","steelblue")[i_color],
  xlab = "Volumen util de cilindros [in^3]",
  ylab = "Potecia [hp]",
  zlab = "Peso [lb x 1000]"
)
g$plane3d(modelo,draw_lines=TRUE, lty="dotted")

# Definir valores de los predictores para vehículos no incluidos en el conjunto mtcars
disp <- c(246.54, 185.015, 317.097, 403.338, 325.263,
          336.128, 200.359, 327.478, 232.06, 382.015)
wt <- c(3.307, 2.965, 3.699, 4.178, 3.744,
        3.804, 3.050, 3.756, 3.226, 4.059)
datos_nuevos <- data.frame(disp, wt)

# Usar el modelo para predecir el rendimiento de otros modelos
hp_est <- predict(modelo, newdata = datos_nuevos)
datos_nuevos <- cbind(datos_nuevos, hp_est)

# Mostrar los resultados
cat("Predicciones:\n")
print(datos_nuevos)

```

### Predictores categóricos no dicotómicos

```{r }
library(dummy)

# Crear una matriz de datos.
persona <- 1:9
sexo <- c("F", "F", "M", "M", "M", "M", "F", "M", "F")
tipo <- c("B", "D", "A", "B", "A", "C", "D", "D", "D")
valor <- c(1.68, 2.79, 1.92, 2.26, 2.1, 2.63, 2.19, 3.62, 2.76)
datos <- data.frame(persona, sexo, tipo, valor)

# Crear variables artificiales.
datos.dummy <- dummy(datos)
datos.dummy[["sexo_F"]] <- NULL
datos.dummy[["tipo_A"]] <- NULL
datos.dummy[["valor"]] <- datos[["valor"]]

# Crear y mostrar el modelo de RLM usando variables indicadoras
modelo <- lm(valor ~ sexo_M + tipo_B + tipo_C + tipo_D, datos.dummy)
print(modelo)

# Crear y mostrar el modelo de RLM dejando el trabajo a lm().
modelo_directo <- lm(valor ~ sexo + tipo, datos)
print(modelo_directo)

```

### Ajuste de un modelo de RLM

R-aquared aumenta siemopre que se agregan más predictores al modelo incluso si esos predictores no contribuyen significativamente a explicar los datos --> Falsa sensacion de mejora del modelo

**R^2 Ajustado**

- R^2 ajustado < R^2 indica presencia de predictores irrelevantes

- R^2 ajustado ~ R^2 sugiere que variables agregadas son relevantes para el modelo

**Principio de parsimonia:** Entre múltiples explicaciones o modelos que describen un fenomeno se debe preferir el más simple

Podemos comparar varios modelos mediante el AIC y el BIC

Mientras menor sean estos, mejor es el modelo

Ahora, solo nos queda ver si es que este modelo con menor AIC y BIC presenta diferencias significativas con el/los otro/s modelo/s y para esto se utiliza  el estadístico F mediante `anova(modelo1,...,modelon)`

### **¿Qué son el AIC y el BIC?**

1. **AIC (Criterio de Información de Akaike):**
   - Mide la calidad de un modelo ajustado penalizando la complejidad del modelo (número de variables). 
   - **Interpretación:** Un AIC más bajo indica un modelo mejor, considerando tanto el ajuste como la simplicidad.
   - **Foco:** Balance entre buen ajuste y evitar el sobreajuste.

2. **BIC (Criterio Bayesiano de Schwarz):**
   - Similar al AIC, pero penaliza con más fuerza los modelos con demasiadas variables.
   - **Interpretación:** Al igual que el AIC, un valor más bajo indica un modelo preferible.
   - **Foco:** Favorece modelos más simples, especialmente cuando el tamaño de los datos es grande.

---

### **Prueba para comparar modelos en R usando ANOVA:**

Si tienes dos o más modelos ajustados y deseas verificar si las diferencias en sus AIC o BIC son significativas, puedes usar la función `anova()`.

#### **Ejemplo en R:**
Supongamos que tienes dos modelos ajustados:
- `modelo1`: Un modelo más simple.
- `modelo2`: Un modelo más complejo (con más predictores).

```r
# Comparar los modelos con ANOVA
anova(modelo1, modelo2)
```

#### **¿Qué hace?**
- Calcula un **estadístico \( F \)** para evaluar si el modelo más complejo mejora significativamente el ajuste.
- Si el **p-valor** es pequeño (por ejemplo, \( p < 0.05 \)), el modelo más complejo es significativamente mejor.
- Si el **p-valor** es grande, no hay evidencia suficiente para preferir el modelo más complejo.

---

### **Resumen:**
- **AIC y BIC:** Métricas que balancean el ajuste del modelo y la simplicidad, siendo BIC más estricto.
- **`anova()` en R:** Una herramienta para comparar si la diferencia en ajuste entre modelos (como reflejan AIC o BIC) es significativa, basándose en un análisis estadístico.

```{r }
library(dplyr)

# Cargar y filtrar los datos.
datos <- mtcars %>% filter(wt > 2 & wt < 5)

# Ajustar el modelo nulo, sin predictores, solo intercepto.
modelo_0 <- lm(hp ~ 1, data = datos)

# Ajustar un modelo con volumen de los cilindros como predictor.
modelo_1 <- lm(hp ~ disp, data = datos)

# Ajustar un modelo añadiendo el peso como predictor.
modelo_2 <- lm(hp ~ disp + wt, data = datos)

# Mostrar AIC y BIC de los modelos
cat("Modelo 0: AIC =", AIC(modelo_0), "\n")
cat("Modelo 1: AIC =", AIC(modelo_1), "\n")
cat("Modelo 2: AIC =", AIC(modelo_2), "\n")
cat("\n")
cat("Modelo 0: BIC =", BIC(modelo_0), "\n")
cat("Modelo 1: BIC =", BIC(modelo_1), "\n")
cat("Modelo 2: BIC =", BIC(modelo_2), "\n")

# Comparar los modelos.
comparacion <- anova(modelo_0, modelo_1, modelo_2)
cat("\n")
cat("Prueba de bondad de ajuste:\n")
print(comparacion)

```

### Seleccion de predictores

#### Regresión Jerarquica

Método que consiste en incorporar predictores al modelo en un **orden específico** basado en su importancia, respaldado por investigaciones previas o razones justificadas. Este enfoque se utiliza para probar teorías y evaluar el impacto incremental de variables adicionales en el modelo.

En **R**, se puede implementar utilizando la función `update(object, formula)`, que permite agregar o eliminar variables del modelo:
- **`object`:** Modelo previamente ajustado (e.g., con `lm()`).
- **`formula`:** Nueva fórmula para el modelo. La notación `.` indica "todo lo que hay en el lado izquierdo/derecho de la fórmula".

Este método es útil para evaluar de manera estructurada la contribución de nuevos predictores, pero requiere un conocimiento previo sólido y justificado sobre las variables incluidas.

--- 

Para el codigo sgte basandonos en bibliografia agregamos en orden de importancia las variables:

disp, cyl, carb, wt, vs

```{r Regresion jerarquica}

library(dplyr)
# Cargar y filtrar datos
datos <- mtcars %>% filter(wt > 2 & wt < 5) %>%
  mutate_at(c("cyl", "vs","am","gear", "carb"), as.factor)

# ajustar el modelo incial con el volumen
# de los celendros como predictor
modelo_1 <- lm(hp ~ disp, data = datos)

# Incorporaar al modelo el número de cilindros y verificar su utilidad
modelo_2 <- update(modelo_1, . ~ . + cyl)
print(anova(modelo_1, modelo_2), signif.legend = FALSE)
```
Notamos que cyl no aporta la modelo puesto que el p-valor asociado es 0.1031 que es considerablemente mayor a 0.05

```{r Seguir ajustando el modelo}

# Reemplazar el número de cilindros por el numero de carburadores y verificar su utilidad 

modelo_3 <- update(modelo_2, . ~ . - cyl + carb)
cat("\n")
print(anova(modelo_1, modelo_3), signif.legend = FALSE)
```
La variable carb si genera un mejor ajuste por lo que lo mantendremos en el modelo

Ahora, en este ultimo modelo la variable cyl seguirá siendo irrelevante? Veamos

```{r Volver a agregar variable cyl}
modelo_4 <- update(modelo_3, . ~ . + cyl)
print(anova(modelo_3, modelo_4), signif.legend = FALSE)
```
Notamos que agregar la variable cyl a este modelo sí ayuda a mejorarlo
Veamos si agregar wt mejora esto o no

```{r Agregamos wt}
modelo_5 <- update(modelo_4, . ~ . + wt)
print(anova(modelo_4, modelo_5), signif.legend = FALSE)
```

Vemos que el peso no aporta un mejor ajuste por lo que reemplazemos wt por vs

```{r Reemplazar wt por vs}
# Actualizamos modelo 5 quitando wt y agregandole vs
# Modelo 6 es el resultante y lo comparamos con el 4 que es el que no contiene wt
modelo_6 <- update(modelo_5, . ~ . - wt + vs)
print(anova(modelo_4, modelo_6), signif.legend = FALSE)
```

Notamos que agregar vs tampoco mejora el modelo por lo que nos quedamos con el modelo 4 que contiene solo disp, carb, cyl

```{r Mostrar modelo final}
# Finalmente mostramos el modelo obtenido
cat("\n\n")
cat("Modelo obtenido con regresión jerárquica:\n")
cat("-----------------------------------------\n")
print(summary(modelo_4), signif.legend = FALSE)

```

#### Regresion Paso a Paso

##### Seleccion hacia adelante

- Se escoge la variable más prometedora para agregarla al modelo (Se puede seleccionar según correlación más alta o la que conlleva mayor aumento de coeficiente de determinación o la que disminuye más el AIC del modelo, etc)

- Si el predictor seleccionado aumenta la capacidad predictica del modelo entonces nos lo quedamos, sino, se descarta. Repetimos el proceso para demás variables.

- Se detiene la búsqueda cuando ya ninguna variable mejora el modelo

> Agregar el que tiene el mayor sum of sq

```{r Regresion paso a paso hacia adelante}
library(dplyr)
# Cargar y filtrar datos
datos <- mtcars %>% filter(wt > 2 & wt < 5) %>%
  mutate_at(c("cyl", "vs","am","gear", "carb"), as.factor)

# ajustar el modelo nulo y completo
nulo <- lm(hp ~ 1, data = datos)
completo <- lm(hp ~ ., data = datos)

cat("Seleccion hacia adelante:\n")

# Evaluar variables para incorporar
paso <- add1(nulo,scope=completo, test="F")
print(paso, digits=3, signif.legend = FALSE)

```

Notamos que la variable que genera la mayor **reduccion significativa de varianza no explicada** es `cyl` puestp que tiene el mayor `Sum of Sq`


```{r Agregar cyl al modelo nulo}
modelo <- update(nulo, . ~ . + cyl)

# Evaluar variables para incorporar
paso <- add1(modelo, scope = completo, test = "F")
print(paso, digits=3, signif.legend = FALSE)
```

Repetimos el proceso y nos damos cuenta que la siguiente variable a agregar al modelo es carb porque presenta la mayor reduccion en la varianza

```{r Agregar carb al modelo actual}
modelo <- update(modelo, . ~ . + carb)

# Evaluar variables para incorporar
paso <- add1(modelo, scope = completo, test = "F")
print(paso, digits=3, signif.legend = FALSE)
```

Notamos que podemos agregar disp para mejorar el modelo sin embargo en la lectura no se realizó por lo que no ejecutaremos esta seccion

```{r Agregar disp al modelo actual, eval=FALSE}
modelo1 <- update(modelo, . ~ . + disp)

# Evaluar variables para incorporar
paso <- add1(modelo1, scope = completo, test = "F")
print(paso, digits=3, signif.legend = FALSE)

print(anova(modelo, modelo1), signif.legend = FALSE)
```

Seguimos con el codigo

```{r Mostrar resultados para el modelo con cyl y carb}
# Mostrar los coeficientes del modelo conseguido.
cat("\nModelo obtenido:\n")
print(modelo[["coefficients"]])

```
##### Eliminación hacia atras

- Se comienza desde un modelo completo que incluye todas las variables

- Va eliminando predictores, el que menos aporte al modelo. Si la eliminación de este último mejora el modelo entonces se elimina de forma definitiva

- Eliminamos hasta que no es posible eliminar más predictores sin perjudicar al modelo

Ahora veamos con eliminacion hacia atras

> Quitar el que tiene el menor F

```{r Eliminacion hacia atras}
library(dplyr)
# Cargar y filtrar datos
datos <- mtcars %>% filter(wt > 2 & wt < 5) %>%
  mutate_at(c("cyl", "vs","am","gear", "carb"), as.factor)

# ajustar el modelo completo

completo <- lm(hp ~ ., data = datos)

paso <- drop1(completo, test="F")
print(paso, digits=3, signif.legend = FALSE)

```
Quitamos wt puesto que tiene el menor F

```{r quitar wt}

# Quitar wt
modelo <- update(completo, . ~ . - wt)

# Evaluar nuevas vars a eliminar
paso <- drop1(modelo, test="F")
print(paso, digits=3, signif.legend = FALSE)

```

Notamos que debemos quitar drat puesto que tiene el menor estadístico F

```{r quitar drat}

# Quitar drat
modelo <- update(modelo, . ~ . - drat)

# Evaluar nuevas vars a eliminar
paso <- drop1(modelo, test="F")
print(paso, digits=3, signif.legend = FALSE)

```
Seguimos viendo que podemos quitar mpg a pesar de que en la lectura no se realizó

```{r quitar mpg}

# Quitar mpg
modelof <- update(modelo, . ~ . - mpg)

# Evaluar nuevas vars a eliminar
paso <- drop1(modelof, test="F")
print(paso, digits=3, signif.legend = FALSE)


print(anova(modelo, modelof), signif.legend = FALSE)
```

Notamos que quitar o no mpg no presenta diferencias significativas con el modelo
Pero siguiendo el principio de parsimonia es mejor quitarla para tener un modelo con menos variables.

```{r Mostrar resultados para el modelo con sin wt y sin drat}
# Mostrar los coeficientes del modelo conseguido.
cat("\nModelo obtenido:\n")
print(modelo[["coefficients"]])

```

##### Regresion Escalonada

- Combina los enfoques anteriores. Parte desde un modelo vacío o completo y alterna entre agregar y elimina predictores.

**IMPORTANTE:** Solo debemos usar estos métodos si estamos explorando datos.

### **Resumen preciso de la función `step()`**

1. **¿Qué hace?**
   - Implementa selección paso a paso de predictores usando criterios como **AIC** o **BIC**.

2. **Argumentos principales:**
   - **`object`:** Modelo inicial (e.g., `lm()` o `glm()`).
   
   - **`scope`:** Rango de búsqueda, definido como:
     - **`lower`:** Modelo más simple (mínimas variables).
     - **`upper`:** Modelo más complejo (todas las variables).
     
   - **`direction`:** Tipo de selección:
     - `"forward"`: Hacia adelante (agregar variables).
     - `"backward"`: Hacia atrás (eliminar variables).
     - `"both"`: Regresión escalonada.
     
   - **`trace`:** Imprime el progreso (`TRUE`) o lo oculta (`FALSE`).
   
   - **Criterio de penalización (`k`)**:
     - Por defecto \( k = 2 \) (AIC).
     - Cambiar a \( k = \log(n) \) para usar BIC.

3. **¿Cómo decide?**
   - Evalúa agregar o eliminar variables en cada paso, seleccionando la que más reduzca el **AIC** o **BIC**.

4. **Ventaja:**
   - Simplifica y optimiza la selección de predictores en modelos de regresión.

```{r Regresion escalonada usando step()}

library(dplyr)
# Cargar y filtrar datos
datos <- mtcars %>% filter(wt > 2 & wt < 5) %>%
  mutate_at(c("cyl", "vs","am","gear", "carb"), as.factor)

# ajustar el modelo nulo y completo
nulo <- lm(hp ~ 1, data = datos)
completo <- lm(hp ~ ., data = datos)

# Realiza regresión escalonada usando el menor BIC
# como criterio (aunque se reporta como AIC), bajando
# (temporalmente) el número de cifras significativas
# y el ancho máximo de la pantalla al imprimir.
opt <- options(digits = 2, width = 54)
modelo <- step(nulo, scope = list(lower = nulo, upper = completo),
               direction = "both", k = log(nrow(datos)),
               test = "F", trace = 1)
options(digits = opt[[1]], width = opt[[2]])

# Mostrar los coeficientes del modelo conseguido
cat("\nModelo obtenido:\n")
print(modelo[["coefficients"]])


```

#### Busqueda exhaustiva pag 277(18)

### Confiabilidad de un modelo RLM

1. La variable de respuesta debe ser cuantitativa y continua, sin restricciones para su variabilidad.  
2. Los predictores deben ser cuantitativos o dicotómicos (de ahí la necesidad de variables indicadoras para manejar más de dos niveles).  
3. Los predictores deben tener algún grado de variabilidad (su varianza no debe ser igual a cero). En otras palabras, no pueden ser constantes.  
4. Cada predictor debe estar relacionado linealmente con la respuesta.  
5. La distribución de los residuos debe ser cercana a la normal centrada en cero. SHAPIRO
6. La variabilidad de los residuos debe ser aproximadamente constante (homocedasticidad). nvcTest
7. Los residuos deben ser independientes entre sí. durbinWatson
8. No debe existir multicolinealidad. Esto significa que no deben darse relaciones lineales **fuertes** (coeficientes de correlación altos) entre dos o más predictores. VIF
9. Las estimaciones de los coeficientes del modelo no deben estar alterados por unos pocas observaciones influyentes.  

Para la 8 utilizamos el factor de inflacion de varianza VIF

#### VIF 

- VIF = 1 no hay multicolinealidad
- 1 < VIF <= 5   multicolinealidad moderada, no hay que preocuparse
- 5 < VIF <= 10  multicolinealidad preocupante, podría afectar significativamente los datos
- VIF > 10       multicolinealidad severa

```{r Calcular factores de inflacion de varianza}
vif(modelo)
```

Para la 9 utilizamos influencePlot

### Calidad predictiva de un modelo de RLM

Es igual que con RLS



