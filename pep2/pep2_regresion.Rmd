---
title: "pep2 regresion"
author: "Forma 6"
date: "2024-01-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

El gobierno también quiere saber si es posible construir un modelo predictivo del consumo eléctrico d elos hogares chilenos con un error menor a 2 Kwh con la misma muestra proporcionada.

Se pide construir un modelo de regresión adecuado para responder la pregunta asignada que use entre 2 y 5 predictores, asegurando que el modelo obtenido sea confiable (Considere VIF >= 5 como evidencia de multicolinealidad problemática). Determine si la calidad predictiva del modelo satisface los requerimientos del gobierno evalúandolo con 499 iteraciones de bootstrapping (usando la semilla 131)

```{r Definir semilla}
library(car)
library(dplyr)
library(ggpubr)
library(psych)

# Definimos semilla
set.seed(131)

# Leemos los datos
datos <- read.csv("EI-2024-2-PE2-Datos-Forma-06.csv")

# Con la funcion str verificamos que el tipo de datos esté correcto
str(datos)

# Notamos que macro_zona, franja y sobre_cons hay que convertirlos a factores puesto que son variables categoricas/dicotómicas
datos$macro_zona <- as.factor(datos$macro_zona)
datos$franja <- as.factor(datos$franja)
datos$sobre_cons <- as.factor(datos$sobre_cons)

str(datos)

# Seleccionamos datos de entrenamiento y de prueba
datos_entren <- datos[1:70,] # fila 1 a 70 y todas las columnas
datos_prueba <- datos[71:100,]
```

Con los datos ya filtrados preparamos la variable de respuesta y los predictores

```{r Seleccionar predictor}
nombre_respuesta <- "consumo"

# Extraer solo las columnas numéricas para revisar correlación
datos_num <- datos_entren[, sapply(datos_entren, is.numeric)]

i_respuesta_resto <- which(colnames(datos_num)==nombre_respuesta) # Indice de la columna de la var de rpta

# Calcular la matriz de correlación
correlacion <- cor(datos_num[ , -i_respuesta_resto], y = datos_num[[nombre_respuesta]])

cat("Correlacion con consumo:\n")
print(correlacion)
```
Asumiendo que el mejor predictor sería el que tiene la mayor correlacion con la variable de respuesta entonces seleccionamos el máximo

```{r seleccionar maximo}
i_mejor <- which(correlacion == max(abs(correlacion)))

# Seleccionamos 9no predictor
#predictor <- colnames(datos_resto)[i_mejor]
predictor <- rownames(correlacion)[i_mejor]
cat("La variable seleccionada es: ",predictor)
```




```{r Ajuste del modelo}
# Definimos modelo mínimo, en este caso modelo nulo
modelo_nulo <- lm(consumo ~ 1, data = datos_entren)

# Definimos modelo máximo, en este caso consideramos a todas las variables
modelo_rlm_max <- lm(consumo ~ . ,data = datos_entren)

modelo_rlm <- step(modelo_nulo, scope = list(lower = modelo_nulo, upper = modelo_rlm_max),
               direction = "both",
               test = "F", trace = 1)

# Mostrar los coeficientes del modelo conseguido
cat("\nModelo obtenido:\n")
print(modelo_rlm[["coefficients"]])
```

Notamos que se seleccionaron 7 variables cuando debimos obtener entre 2 y 5 por lo que tendremos que eliminar dos de las que ya están agregadas y esto lo haremos mediante una eliminacion hacia atrás a la variable que tenga el menor F-value

En este caso notamos que sucede con res_term por lo que lo quitaremos del modelo

```{r}
# Actualizamos el modelo quitando res_term
modelo_rlm <- update(modelo_rlm, . ~ . - res_term)
print(summary(modelo_rlm))
```

Notamos que ahora correspondería quitar n_elec_gr

```{r}
# Actualizamos el modelo quitando res_term
modelo_rlm <- update(modelo_rlm, . ~ . - n_elec_gr)
print(summary(modelo_rlm))
```

y con esto ya cumplimos con que el modelo posee entre 2 y 5 predictores

---

Evaluando la confiabilidad del modelo conseguido...

  1. Que no existan niveles inaceptables de multicolineadlidad
  2. Prueba de curvatura
  3. Normalidad de los residuos
  4. Prueba de homocedasticidad
  5. Prueba de independecia de los residuos
  6. Revisar que relaciones entre predictores y var de rpta sean aproximadamente lineales

```{r Que no existan niveles inaceptables de multicolineadlidad}
cat("Factores de inflación de la varianza:\n")
print(vif(modelo_rlm))
cat("Estadísticos de tolerancia:\n")
print(1 / vif(modelo_rlm))
```
Vemos que hay indicios de multicolinealidad problemática en 2 casos:

- horas_uso
- superf

Eliminemos la que presenta el mayor valor y luego sigamos evaluando.

```{r Eliminemos el que presenta multicolinealidad moderada}
rlm <- update(modelo_rlm, . ~ . - horas_uso)

cat("Factores de inflación de la varianza:\n")
print(vif(rlm))
cat("Estadísticos de tolerancia:\n")
print(1 / vif(rlm))
```
Notamos que ahora todos los predictores presentan un VIF menor a 5, hemos eliminado gran parte de la multicolinealidad presente en el modelo anterior manteniendo 4 predictores.


Revisemos la prueba de curvatura para este modelo

```{r Prueba de curvatura RLM}
cat("Prueba de curvatura:\n")
residualPlots(modelo_rlm, type = "rstandard", terms = ~ 1, col = "steelblue", pch = 20, col.quad = "red")
```

Se ve cierta curvatura, pero no se ve un patrón preocupante, aunque existe cierta tendencia a patrones por sobre la línea de regresión. La prueba de curvatura también apunta en este sentido y segun el p-valor es mayor a 0.05 por lo que esto sugiere que no se detecta curvatura.

Revisemos ahora la normalidad de los residuos

```{r Normalidad de residuos}
# Grafico qq
qq_res <- ggqqplot(data.frame(Residuos = resid(modelo_rlm)), x = "Residuos", color = "steelblue")
print(qq_res)

sw_res <- shapiro.test(resid(modelo_rlm))
cat("Test de normalidad de los residuos del modelo de RLM:")
print(sw_res)
```

Como p > 0.05 no hay suficiente evidencia para rechazar que los datos siguen una distribucion normal

Ahora verifiquemos la varianza e independencia de los residuos.

```{r Ahora verifiquemos la varianza e independencia de los residuos}
cat("Prueba de varianza del error no constante:\n")
ncvTest(modelo_rlm)

cat("\nIndependencia de los residuos\n")
print(durbinWatsonTest(modelo_rlm))
```

Nos damos cuenta de que entonces la homocedasticidad no se está cumpliendo pero que los residuos sí son independientes.

**Verifiquemos entonces la influencia de valores atípicos** que puedan estar generando esto  mediante la **Distancia de Cook** con el gráfico influencePlot

```{r Valores atipicos}
# Desplegar gráficos de influencia
casos_influyentes <- influencePlot(modelo_rlm, id = list(n = 3))
cat("\nCasos que podrían ser influyentes:\n")
print(casos_influyentes)

```

Notamos que el caso que podría tener mayor influencia atípica es el 66

horas_uso  temp_inv    superf  temp_ver edad_elec 

```{r Verificar si quitar caso influyente}
crPlots(modelo_rlm,
        col = "steelblue", pch = 20, col.lines = c("red", "steelblue"),
        smooth = list(smoother = loessLine, span = 1),
        id = list(method = "r", n = 8, cex = 0.7, location = "lr"))

modelo_rlm2 <- lm(consumo ~ horas_uso + temp_inv + superf + edad_elec, data = datos_entren[-65, ])
crPlots(modelo_rlm,
        col = "steelblue", pch = 20, col.lines = c("red", "steelblue"),
        smooth = list(smoother = loessLine, span = 1),
        id = list(method = "r", n = 8, cex = 0.7, location = "lr"))
```

Ahora verifiquemos nuevamente

```{r Ahora verifiquemos la varianza e independencia de los residuos}
cat("Prueba de varianza del error no constante:\n")
ncvTest(modelo_rlm2)

cat("\nIndependencia de los residuos\n")
print(durbinWatsonTest(modelo_rlm2))
```

quitar el caso 65 nos sirvio para que se cumpla la homocedasticidad

Con esto el modelo cumpliendo con las condiciones antes mencionadas quedaría:

```{r}
print(summary(modelo_rlm2))
```

Y notamos que se cumple tener un Residual Standard error como se pide en el enunciado

